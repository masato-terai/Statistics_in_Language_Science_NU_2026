# Week12: 階層モデル

```{r, include=FALSE}
library(rstan)
library(brms)
library(gt)
library(tidyverse)
library(kableExtra)
library(lme4)
library(patchwork)

rstan_options(auto_write = T)
options(mc.cores = parallel::detectCores())
```


## 事前の確認

- この講義のRプロジェクトを開いていますか？
- 英数字で名前を付けた本日の講義のファイルを作成しましたか？

  - .Rでも.Rmdでもどちらでも大丈夫です。

## 今日の目標

1. 階層モデルについて理論的背景やその仮定について理解する
2. 階層モデルをRで実装し、分析の結果を報告することができる



## 一般化線形モデルからの発展

- 一般線形モデル：従属変数が正規分布に従う（e.g., *t* 検定、分散分析、回帰分析）

  - Week 4 - Week 9

- 一般**化**線形モデル：正規分布以外の分布を扱う

  - Week 10
  
- 一般化線形混合効果モデル（Genealized Linewr **Mixed** Model: GLMM）：一般化線形モデルを拡張。実験計画などではコントロールできない要因（ランダム効果）をモデルに組み込む => 本日

  - マルチレベルモデル（multilevel model）、階層線形モデル（hierarchical linear model）、混合効果モデル（mixed-effects model）などとも呼ばれる

  - 混合効果：これまでの講義で扱ってきた独立変数（固定効果）とランダム効果を1つのモデルで表す

  - 得られたデータには、研究目的とは関係のないノイズが含まれる
  
  - 例.
  
    - 項目を提示する順番の影響
    
    - 項目や参加者が持つ特性

  - 基本的に最尤推定法を用いるモデルを指すが、推定法がマルコフ連鎖モンテカルロ法（MCMC）の場合は、階層ベイズモデルと呼ばれる。階層ベイズモデルは、最尤推定法によるGLMMに比べ、よりデータに合わせた柔軟なモデリングが可能である。

<p class="comment">
どのように高度な手法を使う場合でも、分析の前に平均や分散などの記述統計・図示をもとに、立てた仮説や予測と一致しているかなどの確認が必要です。また、分析に入れる変数も、理論や仮説などから妥当なものを原則入れるべきです。
</p>

## ランダム効果とは

- データにばらつきをもたらす、人間が測定できない・測定しなかった（または原因不明の）個体差の効果

<!-- - GLMMでは個体差を表すパラメータが何かしらの確率分布に従うと仮定する。 -->

<!--   - この個体差を表すパラメータは平均ゼロの正規分布に従うと仮定される。これには明確な根拠がある訳ではなく、観測できない個体差はどのような確率分布に従うか分からないため、とりあえず便利だから正規分布を仮定している。 -->

- ランダム効果を設定するべきか否かの判断は、**「同じ個体（参加者）や場所から何度もサンプリングしているか」**

  - 例
  
    - 各参加者に対し、複数の問題を解かせる
    
    - 4つの学校の複数の学生からデータを取得する

::: .infobox
- 「個体から複数のデータを取る」という実験操作を疑似反復という

  - 「疑似」がつく理由：個体差を消すほどの反復にはなっていないため。個体差などを打ち消すような実験操作ができている場合「反復」とみなせる（個体差や場所差を打ち消すために反復を行う）。
  
:::

<!-- ### 階層の種類：Nested vs. Crossed -->
<!-- （ややこしいから入れるか検討） -->
<!-- - 階層のパターンは大別して以下の二種類ある。分析をする際にはこの二つを書き分けなければならないため、データの構造をきちんと把握しておく必要がある。言語系の研究では、入れ子構造が多いため、この講義では入れ子構造のランダム効果の分析法を行う。 -->

<!-- - 入れ子構造（Nested Random Effects） -->

<!--   - レベル1の階層のあるデータは、レベル2の階層のあるデータのみに属し、別のレベル2のデータには属していない。 -->

<!--     - e.g., 参加者がそれぞれ複数の項目を提示される、学校単位の学力調査 -->

<!-- （図を挿入） -->

<!-- - 交差構造（Crossed Random Effects） -->

<!--   - レベル1の階層のあるデータは、レベル2の階層のあるデータのみに属し、別のレベル2のデータにも属す。 -->

<!--     - e.g., 3人の生徒が3人の教師それぞれに教わる -->


<!-- （図を挿入） -->


## ランダム切片モデル

- 切片の値が個体差（e.g., 参加者）によって異なることを仮定したモデル

  - 例. 指導法Aと指導法Bの効果を比較検証したい（事後テストの得点を目的変数として分析）。この場合、テスト得点は指導法の効果による影響だけでなく、生徒の個人差によって異なると仮定

```{r, include=FALSE}
# データ作成
set.seed(123)
n_students <- 10
n_obs <- 5

students <- tibble(
  student_id = factor(1:n_students),
  intercept = rnorm(n_students, mean = 50, sd = 5),
  slope = rnorm(n_students, mean = 2, sd = 0.5)
)

study_time_seq <- seq(0, 10, length.out = n_obs)

data <- students %>%
  group_by(student_id) %>%
  do({
    study_time = study_time_seq
    score = .$intercept + .$slope * study_time + rnorm(n_obs, 0, 3)
    tibble(study_time, score)
  }) %>%
  ungroup()

# 各モデルをフィット
model_intercept <- lmer(score ~ study_time + (1 | student_id), data = data)
model_slope     <- lmer(score ~ study_time + (0 + study_time | student_id), data = data)
model_both      <- lmer(score ~ study_time + (study_time | student_id), data = data)

# 予測値を追加
data$pred_intercept <- predict(model_intercept)
data$pred_slope     <- predict(model_slope)
data$pred_both      <- predict(model_both)

# 固定効果の係数取得
fixef_intercept <- fixef(model_intercept)
fixef_slope     <- fixef(model_slope)
fixef_both      <- fixef(model_both)

# ランダム切片モデルの描画
p1 <- ggplot(data, aes(x = study_time, color = student_id)) +
  geom_line(aes(y = pred_intercept)) +
  geom_abline(intercept = fixef_intercept[1], slope = fixef_intercept[2], color = "black", linetype = "dashed", linewidth = 1) +
  labs(title = "ランダム切片モデル", x = "勉強時間", y = "英語のテスト得点") + ylim(30, 100)

# ランダム係数モデル（切片は固定）の描画
p2 <- ggplot(data, aes(x = study_time, color = student_id)) +
  geom_line(aes(y = pred_slope)) +
  geom_abline(intercept = fixef_slope[1], slope = fixef_slope[2], color = "black", linetype = "dashed", linewidth = 1) +
  labs(title = "ランダム係数モデル（切片は固定）", x = "勉強時間", y = "英語のテスト得点") + ylim(30, 100)

# ランダム切片 + 係数モデルの描画
p3 <- ggplot(data, aes(x = study_time, color = student_id)) +
  geom_line(aes(y = pred_both)) +
  geom_abline(intercept = fixef_both[1], slope = fixef_both[2], color = "black", linetype = "dashed", linewidth = 1) +
  labs(title = "ランダム切片＋係数モデル", x = "勉強時間", y = "英語のテスト得点") + ylim(30, 100)
```

```{r, echo=FALSE}
p1 + plot_layout(guides = "collect") & theme(legend.position = "bottom")
```

## ランダム係数モデル

- モデル内の独立変数の係数が個体差によって異なることを仮定したモデル

  - 例. 指導法Aと指導法Bの効果を比較検証したい（事後テストの得点を目的変数として分析）。この場合、指導法の効果は生徒の個人差によって異なる仮定

```{r, echo=FALSE}
(p1 | p2) + plot_layout(guides = "collect") & theme(legend.position = "bottom")
```


## ランダム切片 & 係数モデル

```{r, echo=FALSE}
p3 +
  plot_layout(guides = "collect") &
  theme(legend.position = "bottom")

```


## GLMMを行うときの留意点

### 推定方法
- 頻度統計の場合のマルチモデルの推定には最尤法が使われる（Maximum Likelihood）。目安として50人程度のサンプルサイズが最低限必要（変量効果の分散成分が過小推定される）。しかし、サンプルサイズがどうしても少なくなる場合もある。そこで、制限つき最尤法が開発され、ソフトウェアではこちらが採用されている場合が多い。サンプルサイズが十分に多い場合、最尤法の方が制限つき最尤法よりも推定精度がいい（標準誤差が小さい）。また制限つき最尤法では固定効果について尤度を計算しないため、情報量基準を用いたモデル比較を行うことができない。

- 最尤法、制限つき最尤法も従属変数の正規性と分散均一性の仮定がある。サンプルサイズが十分に大きい場合、切片や回帰係数の推定値は分布が歪んでいることによるバイアスを受けにくい。しかし、標準誤差は正しく推定されなくなるため、標準誤差を使って算出される有意性検定や信頼区間の推定にバイアスが発生することに注意が必要。

### データセットの構造に注意
- (「**Week 11: Tidyverseパッケージによるデータの加工と可視化**」を参照してください)

- これまでに使用してきたデータセットが必ずしもGLMMの分析に合うものではない

- 各行には、一人の参加者の各項目が含まれているべきである

  - この形式にしておけば、どのような分析にも対応できる（Tidy dataとも呼ばれる）

- Tidy dataの例
```{r, echo=FALSE, tab.cap= "Tidy dataの例"}
dat.demo <- read.csv("sample_data/AJ.csv")[,c(1:2, 9)]

head(dat.demo, 5)
```


### 計算の負荷が大きい
- これまでに紹介した分析とは異なり、結果が出力されるまでに時間がかかります。モデルの変数が多く、ランダム効果にも複数の変数を含む場合、数日かかることもあります。

## ハンズオンセッション

### データの読み込み

### パッケージのインストール

- ```lme4```パッケージを使用します

```{r, warning=FALSE, message=FALSE}
library(lme4)
```

- 処理にかかる時間を計測するため、```tictoc```パッケージを使います。

```{r, warning=FALSE, message=FALSE}
#install.packages("tictoc")
library(tictoc)
```

- コンピュータのスペックはこんな感じです

```{r, echo=FALSE}
benchmarkme::get_cpu()
```

```{r, echo=FALSE}
benchmarkme::get_ram()
```


- Terai et al. (2024)のデータを使用します。

```{r}
dat <- read.csv("../stat_class_2025/sample_data/AJ.csv")
```

```{r}
dat$Itemtype <- factor(dat$Itemtype, levels = c("Baseline", "JE", "Eonly"))
contrasts(dat$Itemtype) <- contr.treatment(3)

contrasts(dat$Itemtype)
```

- 連続値の場合中心化します
```{r, warning=FALSE, message=FALSE}
#install.packages("tidyverse")
library(dplyr)
dat2 <- dat %>%
  group_by(subject) %>%
  mutate(across(c("pres.order", "Length"), ~scale(.x)[,1],.names = "z.{col}")) %>%
  ungroup()
```

- 切片のみ（実験項目、参加者）のモデル

  - 従属変数：正答（1: 正解、2: 不正解）
  
  - 独立変数：コロケーションの種類

```{r}
tic()
res.1 <- glmer(
  res ~ Itemtype +
  (1|subject) + (1|itemID),
  family = binomial(link = "logit"),
  data = dat2,
  control = glmerControl(optimizer = "bobyqa")
               )
toc()
```

```{r}
summary(res.1)
```

- 切片と係数のモデル

- モデルが上手く収束しなかった

```{markdown}
tic()
res.2 <- glmer(
  res ~ Itemtype +
  (1 + pres.order|subject) + (1|itemID),
  family = binomial(link = "logit"),
  data = dat2,
  control = glmerControl(optimizer = "bobyqa")
               )
toc()
```

- **出力結果：**

> 警告:  Model failed to converge with max|grad| = 0.00228081 (tol = 0.002, component 1) 警告:  Model is nearly unidentifiable: very large eigenvalue
> - Rescale variables?


- 中心化した変数だとうまくいった
```{r}
tic()
res.3 <- glmer(
  res ~ Itemtype +
  (1 + z.pres.order|subject) + (1|itemID),
  family = binomial(link = "logit"),
  data = dat2,
  control = glmerControl(optimizer = "bobyqa") #スムーズに推定を行うためにこれを設定します
               )
toc()
```

```{r}
summary(res.3)
```

- 95% 信頼区間の算出（CI）
```{r}
se <- sqrt(diag(vcov(res.3)))

# table of estimates with 95% CI
tab <- cbind(
  Est = fixef(res.3),
  LL = fixef(res.3) - 1.96 * se,
  UL = fixef(res.3) + 1.96 * se
  )

tab
```

- ```confint()```でも算出可能

  - こちらは推定法の関係で時間がかかる

```{r}
tic()
confint(res.3)
toc()
```

- オッズ比

```{r}
exp(tab)
```

- モデル比較

  - 尤度比検定の結果、係数を考慮したモデルの方がよりAICが有意に低かった

```{r}
anova(res.1, res.3)
```


<!-- - ```performance```パッケージでモデルの当てはまり度合いを確認 -->

<!-- ```{r, warning=FALSE, message=FALSE} -->
<!-- #install.packages("performance") -->
<!-- library(performance) -->
<!-- compare_performance(res.1, res.3, rank = TRUE, verbose = FALSE) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- plot(compare_performance(res.1, res.3, rank = TRUE, verbose = FALSE)) -->
<!-- ``` -->

- 図示
```{r, warning=FALSE, message=FALSE}
#install.packages("ggeffects")
library(ggeffects)
eff <- ggpredict(res.3, terms = "Itemtype")
plot(eff)
```

- モデル診断

  - ```performance```パッケージが便利

  - VIF（多重共線性についての指標）

    - 今回は1変数しかないので確認の必要はない

```{markdown}
#install.packages("performance")
library(performance)
check_collinearity(モデルの結果を格納した変数名)
```

  - 外れ値

  - *p* ≥ .05: 残差はモデル期待通り（≒一様分布）
  
  - *p* < .05: 残差がモデル期待とズレている（≒モデルのミスフィット）

```{r}
library(performance)
check_residuals(res.3)
```

```{r}
plot(check_residuals(res.3))
```


<!--   - 自己相関（Auto-correlation） -->

<!-- - 帰無仮説：残差に自己相関はない（＝独立している） -->

<!-- - 対立仮説：残差に自己相関がある -->

<!-- ```{r} -->
<!-- check_autocorrelation(res.3) -->
<!-- ``` -->


::: infobox
ランダム効果を組み込んだ回帰分析を行う主な理由の一つに、**縮約（shrinkage）**という効果があります。縮約とは、各グループの極端な推定値が、全体の平均値（プーリングされた平均）に引き寄せられる現象を指します。この効果により、サンプル数が少ないグループや外れ値の影響が軽減され、より頑健で一般化可能な推定が可能になります。しかし、極端な推定値が実際に意味のあるものであった場合、縮約によってその効果が過小評価されてしまうという問題があります。たとえば、複数の種類の薬の効果を検証したい場合に、薬の種類をランダム効果に含めてモデルを構築すると、ある薬が他と明らかに異なる効果を示していたとしても、縮約によってその差が「なかったこと」になってしまう可能性があります。このようなケースでは、薬の種類ごとの効果を明確に比較したいという研究目的があるため、薬の種類をランダム効果としてではなく独立変数（固定効果）としてモデルに含める必要があります。**つまり、何をランダム効果として設定するのかを研究課題・仮説の段階で決めておく必要があります。**

```{r, include=FALSE, message=FALSE, warning=FALSE}
dat <- read.csv("sample_data/4-3-1-fish-num-4.csv")
glm <- brm(fish_num ~ temperature * human, family = poisson(), data = dat, seed = 1,
           prior = c(set_prior("", class = "Intercept")))
```

- 以下の図は、気温と参加者の交互作用のモデルです。10番の参加者のデータのみ、右肩下がりとなっています。
```{r, echo=FALSE, warning=FALSE, message=FALSE}
conditions <- data.frame(
  human = c("A","B","C","D","E","F","G","H","I","J"))

eff_1 <- marginal_effects(glm,
                          effects = "temperature",
                          conditions = conditions)
plot(eff_1, points = TRUE)
```

```{r, include=FALSE, message=FALSE, warning=FALSE}
glmm <- brm(
  formula = fish_num ~ temperature + (temperature||human),
  family = poisson(),
  data = dat,
  seed = 1,
  iter = 6000,
  warmup = 5000,
  control = list(adapt_delta = 0.97, max_treedepth = 15)
)

```

- 以下の図は気温と参加者の交互作用ではなく、独立変数に気温、ランダム効果に参加者を含めたモデルです。10番の参加者が他の参加者と同じ右肩上がりの傾向に変わっていることが分かります。
```{r, echo=FALSE, warning=FALSE, message=FALSE}
conditions <- data.frame(
  human = c("A","B","C","D","E","F","G","H","I","J"))

# 図示
eff_2 <- marginal_effects(glmm,
                          re_formula = NULL,
                          effects = "temperature",
                          conditions = conditions)
plot(eff_2, points = TRUE)
```

:::

## 次週までの課題
### 課題内容

1. 小テストに向けて今回の内容を復習する。必ず手でコードを入力してRを実行する。

2. 今回の講義のハンズオンセッションの内容を再度自分のRプログラム上で実行する。**分析の最後に、結果の報告を行うこと。**

### 提出方法
- TACT上で提出。
- 締め切りは今週の木曜日まで

## 参考文献
- 📚久保（2012）『データ解析のための統計モデリング入門』岩波書店

- 📚清水（2014）『個人と集団のマルチレベル分析』ナカニシヤ出版

- 📚竹内・水本（編著）（2023）『外国語教育研究ハンドブック【増補版】―研究手法のより良い理解のために』松柏社

- 📚馬場（2019）『RとStanではじめる　ベイズ統計モデリングによるデータ分析入門』講談社

- 📄[村山. (2018). 刺激の効果を侮るなかれ―ランダム刺激効果を含んだ線形混合モデルの重要性と落とし穴―. 基礎心理学研究, 36(2), 236-242.](https://www.jstage.jst.go.jp/article/psychono/36/2/36_36.40/_article/-char/ja/)

- 📄[山口. (2018). 【心理学系】混合効果モデルの利用: 刺激の変量効果への対処. バイオフィードバック研究, 45(2), 93-98.](https://www.jstage.jst.go.jp/article/jjbf/45/2/45_93/_article/-char/ja/)

- 📄[Brysbaert, M. (2025). Applying Mixed-Effects Models in Research on Second Language Acquisition: A Tutorial for Beginners. *Languages, 10*(2), 20.](https://www.mdpi.com/2226-471X/10/2/20)

- 📄[Garcia, G. D. (2024). Bayesian estimation in multiple comparisons. *Studies in Second Language Acquisition*, 1-27.](https://www.cambridge.org/core/journals/studies-in-second-language-acquisition/article/bayesian-estimation-in-multiple-comparisons/ECFBBB9DC96176DB3EDEA45A327759CF)

- 📄[Terai, M., Fukuta, J., & Tamura, Y. (2024). Learnability of L2 collocations and L1 influence on L2 collocational representations of Japanese learners of English. *International Review of Applied Linguistics in Language Teaching, 62*(4), 1959-1983.](https://www.degruyterbrill.com/document/doi/10.1515/iral-2022-0234/html)

- 💻[glmやglmerによるパラメータ推定値と信頼区間をggplot2で描画する (easystats)](https://qiita.com/ocean_f/items/9de4c6bc60616e5a3cf2)

- 💻[Mixed Effects Logistic Regression | R Data Analysis Examples](https://stats.oarc.ucla.edu/r/dae/mixed-effects-logistic-regression/)

- 💻[Crossed vs nested random effects: how do they differ and how are they specified correctly in lme4?](https://stats.stackexchange.com/questions/228800/crossed-vs-nested-random-effects-how-do-they-differ-and-how-are-they-specified)


```{=html}
<style>
.infobox {
  padding: 1em 1em 1em 4em;
  margin-bottom: 10px;
  border: 2px solid orange;
  border-radius: 10px;
  background: #f5f5f5 5px center/3em no-repeat;
}

.beg {
  background-image: url("https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHtu3kBX8P39WYBBAjar9c8c1ladK2SYL6_gEMXFweQfauWVhSvCQP5KELsPX5KNL1uOddLLQ-aeMxv904OW_NFFfANhBYObfBV09KO2EXehrb9kMdCLZY1afsChib-7zIkBJbG6OrbJpM/s400/aisatsu_kodomo_boy.png");}

.caution {
  background-image: url("https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhzMqkpQ7vLUKvumbm6AFwTLQiCe7tlDb2Q0MAiISLsesZHnhj0kbRjB4U3se3UrDIHfIy0hlahyphenhyphenQu-V2tOR2LcV_lX7U8P5a8jtqPYv3Ah4L-JoYi8PhoaoehumGIdp2vrsX0rRyhXqwA/s800/mark_chuui.png");}

p.comment {
background-color: #DBDBDB;
padding: 10px;
border: 1px solid black;
margin-left: 25px;
border-radius: 5px;
font-style: italic;
}

</style>
```